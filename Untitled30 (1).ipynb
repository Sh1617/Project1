{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaxmi1j0foFz",
        "outputId": "30635c89-a1cd-42b4-ac2c-21164ca0e338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 411 users and 35520 repositories\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict\n",
        "\n",
        "class GitHubScraper:\n",
        "    def __init__(self, token: str):\n",
        "        self.headers = {\n",
        "            'Authorization': f'token {token}',\n",
        "            'Accept': 'application/vnd.github.v3+json'\n",
        "        }\n",
        "        self.base_url = 'https://api.github.com'\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _make_request(self, url: str, params: dict = None) -> Dict:\n",
        "        while True:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
        "                sleep_time = max(reset_time - time.time(), 0) + 1\n",
        "                self.logger.warning(f\"Rate limit hit. Sleeping for {sleep_time} seconds\")\n",
        "                time.sleep(sleep_time)\n",
        "            else:\n",
        "                self.logger.error(f\"Error {response.status_code}: {response.text}\")\n",
        "                response.raise_for_status()\n",
        "\n",
        "    def clean_company_name(self, company: str) -> str:\n",
        "        if not company:\n",
        "            return \"\"\n",
        "        cleaned = company.strip().lstrip('@')\n",
        "        return cleaned.upper()\n",
        "\n",
        "    def search_users(self, location: str, min_followers: int) -> List[Dict]:\n",
        "        users = []\n",
        "        page = 1\n",
        "\n",
        "        while True:\n",
        "            self.logger.info(f\"Fetching users page {page}\")\n",
        "            query = f\"location:{location} followers:>={min_followers}\"\n",
        "            params = {'q': query, 'per_page': 100, 'page': page}\n",
        "            url = f\"{self.base_url}/search/users\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response['items']:\n",
        "                break\n",
        "\n",
        "            self.logger.info(f\"Found {len(response['items'])} users on page {page}\")\n",
        "\n",
        "            for user in response['items']:\n",
        "                user_data = self._make_request(user['url'])\n",
        "                cleaned_data = {\n",
        "                    'login': user_data['login'],\n",
        "                    'name': user_data['name'] if user_data['name'] else \"\",\n",
        "                    'company': self.clean_company_name(user_data.get('company')),\n",
        "                    'location': user_data['location'] if user_data['location'] else \"\",\n",
        "                    'email': user_data['email'] if user_data['email'] else \"\",\n",
        "                    'hireable': user_data['hireable'] if user_data['hireable'] is not None else False,\n",
        "                    'bio': user_data['bio'] if user_data['bio'] else \"\",\n",
        "                    'public_repos': user_data['public_repos'],\n",
        "                    'followers': user_data['followers'],\n",
        "                    'following': user_data['following'],\n",
        "                    'created_at': user_data['created_at']\n",
        "                }\n",
        "                users.append(cleaned_data)\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        self.logger.info(f\"Total users fetched: {len(users)}\")\n",
        "        return users\n",
        "\n",
        "    def get_user_repositories(self, username: str, max_repos: int = 500) -> List[Dict]:\n",
        "        repos = []\n",
        "        page = 1\n",
        "\n",
        "        while len(repos) < max_repos:\n",
        "            self.logger.info(f\"Fetching repositories for {username}, page {page}\")\n",
        "            params = {'sort': 'pushed', 'direction': 'desc', 'per_page': 100, 'page': page}\n",
        "            url = f\"{self.base_url}/users/{username}/repos\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response:\n",
        "                break\n",
        "\n",
        "            for repo in response:\n",
        "                repo_data = {\n",
        "                    'login': username,\n",
        "                    'full_name': repo['full_name'],\n",
        "                    'created_at': repo['created_at'],\n",
        "                    'stargazers_count': repo['stargazers_count'],\n",
        "                    'watchers_count': repo['watchers_count'],\n",
        "                    'language': repo['language'] if repo['language'] else \"\",\n",
        "                    'has_projects': repo['has_projects'],\n",
        "                    'has_wiki': repo['has_wiki'],\n",
        "                    'license_name': repo['license']['key'] if repo.get('license') else \"\"\n",
        "                }\n",
        "                repos.append(repo_data)\n",
        "\n",
        "            if len(response) < 100:\n",
        "                break\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return repos[:max_repos]\n",
        "\n",
        "def main():\n",
        "    token = \"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\"  # Replace with your actual GitHub token\n",
        "\n",
        "    # Initialize scraper\n",
        "    scraper = GitHubScraper(token)\n",
        "\n",
        "    # Search for users in Stockholm with >100 followers\n",
        "    users = scraper.search_users(location='Stockholm', min_followers=100)\n",
        "\n",
        "    # Save users to CSV\n",
        "    users_df = pd.DataFrame(users)\n",
        "    users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "    # Get repositories for each user\n",
        "    all_repos = []\n",
        "    for user in users:\n",
        "        repos = scraper.get_user_repositories(user['login'])\n",
        "        all_repos.extend(repos)\n",
        "\n",
        "    # Save repositories to CSV\n",
        "    repos_df = pd.DataFrame(all_repos)\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "    print(f\"Scraped {len(users)} users and {len(all_repos)} repositories\")\n",
        "\n",
        "    # Create README.md\n",
        "    with open('README.md', 'w') as f:\n",
        "        f.write(f\"\"\"# GitHub Users in Stockholm\n",
        "\n",
        "This repository contains data about GitHub users in Stockholm with over 100 followers and their repositories.\n",
        "\n",
        "## Files\n",
        "\n",
        "1. `users.csv`: Contains information about {len(users)} GitHub users in Stockholm with over 100 followers\n",
        "2. `repositories.csv`: Contains information about {len(all_repos)} public repositories from these users\n",
        "3. `fetch_users.py`: Python script used to collect this data\n",
        "\n",
        "## Data Collection\n",
        "\n",
        "- Data collected using GitHub API\n",
        "- Date of collection: {time.strftime('%Y-%m-%d')}\n",
        "- Only included users with 100+ followers\n",
        "- Up to 500 most recently pushed repositories per user\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the users.csv and repositories.csv files\n",
        "files.download('users.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "65_eBZrfkzU9",
        "outputId": "0b5c2b8b-b806-46ce-d33e-baece448e7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_736282d6-6341-45b6-aba2-cd5698ae0935\", \"users.csv\", 58708)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the repositories.csv file\n",
        "files.download('repositories.csv')\n"
      ],
      "metadata": {
        "id": "_AkEpVd0lfGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1."
      ],
      "metadata": {
        "id": "yS8HyrVBa4ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Sort the users by followers in descending order and get the top 5\n",
        "top_users = users_df.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Get the logins of the top users\n",
        "top_user_logins = ', '.join(top_users['login'].tolist())\n",
        "\n",
        "print(\"Top 5 users in Stockholm with the highest number of followers:\")\n",
        "print(top_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3kJ5vuGsDSK",
        "outputId": "26bd5ab0-2e2c-4cde-bfde-abf2ab0c762a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users in Stockholm with the highest number of followers:\n",
            "emmabostian, emilk, mpj, hrydgard, eriklindernoren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2."
      ],
      "metadata": {
        "id": "cWY9RCMSa6m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users.csv file\n",
        "users = pd.read_csv('users.csv')\n",
        "\n",
        "# Sort by followers in descending order and get the top 5\n",
        "top_users = users.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Get the login of the top 5 users\n",
        "top_user_logins = ', '.join(top_users['login'].tolist())\n",
        "print(top_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkxwdHhjtmvD",
        "outputId": "021546a4-6c7d-4b72-b181-4430f429b254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emmabostian, emilk, mpj, hrydgard, eriklindernoren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3."
      ],
      "metadata": {
        "id": "9Xg53ukwa8L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert 'created_at' to datetime\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Get the top 5 earliest registered users\n",
        "earliest_users = users_df.nsmallest(5, 'created_at')\n",
        "\n",
        "# Get the login names in ascending order\n",
        "earliest_user_logins = ', '.join(earliest_users['login'].tolist())\n",
        "\n",
        "# Output the result\n",
        "print(\"Earliest registered users in Stockholm:\", earliest_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okTPv53Sy0xp",
        "outputId": "0ac2eef5-fb3b-4af4-b896-cfc43f50f3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earliest registered users in Stockholm: Mange, kallepersson, fesplugas, etnt, pirelenito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4."
      ],
      "metadata": {
        "id": "fIdNoL-ka9--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out missing licenses\n",
        "licenses = repos_df['license_name'].dropna()\n",
        "\n",
        "# Count the occurrences of each license\n",
        "license_counts = licenses.value_counts()\n",
        "\n",
        "# Get the top 3 most popular licenses\n",
        "top_3_licenses = license_counts.head(3).index.tolist()\n",
        "\n",
        "# Output the result\n",
        "print(\"The 3 most popular licenses are:\", ', '.join(top_3_licenses))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNPkPgDWy_de",
        "outputId": "4cf38e90-d3e3-49aa-df44-df9b386c0350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 3 most popular licenses are: mit, apache-2.0, other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5."
      ],
      "metadata": {
        "id": "otR_TKI-bAt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Clean up the company names\n",
        "users_df['company'] = users_df['company'].str.strip().str.lstrip('@').str.upper()\n",
        "\n",
        "# Count the occurrences of each company\n",
        "company_counts = users_df['company'].value_counts()\n",
        "\n",
        "# Get the company with the highest count\n",
        "most_common_company = company_counts.idxmax()\n",
        "most_common_count = company_counts.max()\n",
        "\n",
        "# Output the result\n",
        "print(\"The majority of developers work at:\", most_common_company)\n",
        "print(\"Number of developers at this company:\", most_common_count)\n"
      ],
      "metadata": {
        "id": "L-g4FKY_zEn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories.csv file\n",
        "repos = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Drop rows where the language is NaN (no language specified)\n",
        "repos = repos.dropna(subset=['language'])\n",
        "\n",
        "# Count the occurrences of each language\n",
        "language_counts = repos['language'].value_counts()\n",
        "\n",
        "# Get the most popular language\n",
        "most_popular_language = language_counts.idxmax()\n",
        "print(f\"The most popular programming language is: {most_popular_language}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIrwYDQzutna",
        "outputId": "a21428a0-618b-4726-ef46-6e0fcc7b7b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most popular programming language is: JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6."
      ],
      "metadata": {
        "id": "lEm_5tvKbIF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load users and repositories data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter users who joined after 2020\n",
        "users_after_2020 = users_df[pd.to_datetime(users_df['created_at']) > '2020-01-01']\n",
        "\n",
        "# Merge with repositories data to get repos only for users who joined after 2020\n",
        "repos_after_2020 = repos_df[repos_df['login'].isin(users_after_2020['login'])]\n",
        "\n",
        "# Filter out missing languages\n",
        "languages_after_2020 = repos_after_2020['language'].dropna()\n",
        "\n",
        "# Count occurrences of each language\n",
        "language_counts_after_2020 = languages_after_2020.value_counts()\n",
        "\n",
        "# Get the second most popular language\n",
        "second_most_popular_language = language_counts_after_2020.index[1]\n",
        "\n",
        "# Output the result\n",
        "print(\"The second most popular programming language among users who joined after 2020 is:\", second_most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-Ad9ivyu-H-",
        "outputId": "004eb9f5-ad60-43d2-e0ec-dc1649f19fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The second most popular programming language among users who joined after 2020 is: TypeScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7."
      ],
      "metadata": {
        "id": "78WndILybKi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out rows with missing language or zero stars\n",
        "repos_with_stars = repos_df[repos_df['stargazers_count'] > 0].dropna(subset=['language'])\n",
        "\n",
        "# Group by language and calculate the average star count per language\n",
        "avg_stars_per_language = repos_with_stars.groupby('language')['stargazers_count'].mean()\n",
        "\n",
        "# Find the language with the highest average stars\n",
        "top_language_by_avg_stars = avg_stars_per_language.idxmax()\n",
        "top_avg_stars = avg_stars_per_language.max()\n",
        "\n",
        "# Output the result\n",
        "print(\"The language with the highest average number of stars per repository is:\", top_language_by_avg_stars)\n",
        "print(\"Average stars per repository:\", top_avg_stars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn4444W5zSk8",
        "outputId": "bf1d9e08-0e89-4cc3-ad7d-bc610f5cb718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language with the highest average number of stars per repository is: RAML\n",
            "Average stars per repository: 981.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8."
      ],
      "metadata": {
        "id": "T9FLBJOEbS39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate leader_strength\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Sort by leader_strength in descending order and get the top 5 users\n",
        "top_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
        "\n",
        "# Output the top 5 users' login in a comma-separated format\n",
        "top_leader_logins = \", \".join(top_leaders['login'])\n",
        "print(\"Top 5 users by leader_strength:\", top_leader_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvc_g1UKzbui",
        "outputId": "e79d0701-5ef3-4cf0-f12e-d3b3089951ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users by leader_strength: spotify, Mojang, fornwall, joearms, EmbarkStudios\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9."
      ],
      "metadata": {
        "id": "4RzJ7VnCbUNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the correlation between followers and public_repos\n",
        "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(\"Correlation between followers and public repositories:\", round(correlation, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpJ-7vz3zkzv",
        "outputId": "94dff5d3-832f-42b9-90ff-0f708b84a64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between followers and public repositories: 0.035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10."
      ],
      "metadata": {
        "id": "0PzmXJmbbVxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Define the independent (X) and dependent (Y) variables\n",
        "X = users_df['public_repos']\n",
        "Y = users_df['followers']\n",
        "\n",
        "# Add a constant to the independent variable for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of public_repos)\n",
        "slope = model.params['public_repos']\n",
        "\n",
        "print(\"Estimated increase in followers per additional repository:\", round(slope, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mStWgk7z8_q",
        "outputId": "df353db0-34e2-4f3a-d63e-0fcb64dee055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated increase in followers per additional repository: 0.228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11."
      ],
      "metadata": {
        "id": "6XtJ2Po-bZFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "repos = pd.read_csv('repositories.csv')\n",
        "\n",
        "if repos['has_projects'].dtype == 'object':\n",
        "    repos['has_projects'] = repos['has_projects'].map({'true': 'TRUE', 'false': 'FALSE'})\n",
        "if repos['has_wiki'].dtype == 'object':\n",
        "    repos['has_wiki'] = repos['has_wiki'].map({'true': 'TRUE', 'false': 'FALSE'})\n",
        "\n",
        "correlation = repos['has_projects'].corr(repos['has_wiki'])\n",
        "\n",
        "print(round(correlation, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz9fyaA7vunB",
        "outputId": "fc62b59d-ebe0-45b6-ac27-e57f4cea13ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the CSV file\n",
        "csv_file = 'repositories.csv'  # Replace with the correct path\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "data = pd.read_csv(csv_file)\n",
        "# Assuming 'data' is your DataFrame with binary columns 'projects_enabled' and 'wiki_enabled'\n",
        "correlation = data['has_projects'].corr(data['has_wiki'])\n",
        "print(f\"The correlation between projects and wiki enabled is: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e38z2gl16F_b",
        "outputId": "7ea3d521-4534-4812-d75d-4d98295589bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The correlation between projects and wiki enabled is: 0.3749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12."
      ],
      "metadata": {
        "id": "4tAqoSrbbdtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('users.csv')\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "average_hireable = data[data['hireable'] == True]['following'].mean()\n",
        "average_non_hireable = data[data['hireable'] == False]['following'].mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = average_hireable - average_non_hireable\n",
        "\n",
        "print(f\"The average following for hireable users minus the average following for non-hireable users is: {difference:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uMF_NOz6rWZ",
        "outputId": "6845fcc0-f1ed-4d6c-e73e-34c16fde7a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average following for hireable users minus the average following for non-hireable users is: 48.389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13."
      ],
      "metadata": {
        "id": "2CAWeGCObnF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = 'users.csv'  # Ensure this path is correct\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Check the first few rows and the data types of the DataFrame\n",
        "print(\"DataFrame Overview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Filter out users without bios\n",
        "df = df[df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of each bio in words\n",
        "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the independent variable (X) and dependent variable (y)\n",
        "X = df['bio_word_count']\n",
        "y = df['followers']  # Adjust the column name as per your dataset\n",
        "\n",
        "# Add a constant to the independent variable (for the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of the bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the regression slope rounded to three decimal places\n",
        "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Cr-PknT6du",
        "outputId": "05ed69e9-2583-4bd0-e763-0543c8bc98cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Overview:\n",
            "             login                      name           company  \\\n",
            "0      emmabostian              Emma Bostian           SPOTIFY   \n",
            "1            emilk           Emil Ernerfeldt    RERUN.IO, EGUI   \n",
            "2              mpj  Mattias Petter Johansson  FUN FUN FUNCTION   \n",
            "3         hrydgard            Henrik Rydgård               NaN   \n",
            "4  eriklindernoren         Erik Linder-Norén               NaN   \n",
            "\n",
            "            location                      email  hireable  \\\n",
            "0  Stockholm, Sweden                        NaN     False   \n",
            "1  Stockholm, Sweden  emil.ernerfeldt@gmail.com     False   \n",
            "2  Stockholm, Sweden                        NaN      True   \n",
            "3  Stockholm, Sweden         hrydgard@gmail.com     False   \n",
            "4  Stockholm, Sweden  eriklindernoren@gmail.com     False   \n",
            "\n",
            "                                                 bio  public_repos  followers  \\\n",
            "0          Front-end Software Engineer @ Spotify\\r\\n            61       6473   \n",
            "1       Rust coder, creator of egui, CTO of rerun.io            71       6266   \n",
            "2                                                NaN           142       5708   \n",
            "3                                                NaN            60       5545   \n",
            "4  ML engineer at Apple. Excited about machine le...            24       5346   \n",
            "\n",
            "   following            created_at  \n",
            "0         15  2014-05-22T17:47:40Z  \n",
            "1         20  2011-10-24T16:40:17Z  \n",
            "2         23  2008-07-22T10:20:27Z  \n",
            "3         25  2009-09-24T18:40:26Z  \n",
            "4         11  2014-06-24T16:31:53Z  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 410 entries, 0 to 409\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   login         410 non-null    object\n",
            " 1   name          402 non-null    object\n",
            " 2   company       262 non-null    object\n",
            " 3   location      410 non-null    object\n",
            " 4   email         247 non-null    object\n",
            " 5   hireable      410 non-null    bool  \n",
            " 6   bio           265 non-null    object\n",
            " 7   public_repos  410 non-null    int64 \n",
            " 8   followers     410 non-null    int64 \n",
            " 9   following     410 non-null    int64 \n",
            " 10  created_at    410 non-null    object\n",
            "dtypes: bool(1), int64(3), object(7)\n",
            "memory usage: 32.6+ KB\n",
            "None\n",
            "\n",
            "Regression slope of followers on bio word count: 6.692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14."
      ],
      "metadata": {
        "id": "oRhMAn10c8uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert the 'created_at' column to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter to keep only weekend entries (Saturday: 5, Sunday: 6)\n",
        "repos_df['day_of_week'] = repos_df['created_at'].dt.dayofweek\n",
        "weekend_repos = repos_df[repos_df['day_of_week'].isin([5, 6])]\n",
        "\n",
        "# Count repositories created by each user on weekends\n",
        "top_weekend_users = weekend_repos['login'].value_counts().head(5)\n",
        "\n",
        "# List of top 5 users' logins\n",
        "top_users_logins = ', '.join(top_weekend_users.index)\n",
        "print(f\"Top 5 users who created the most repositories on weekends: {top_users_logins}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRYI_93rc7Tt",
        "outputId": "1a3744f5-69b6-494f-fe96-d20b6ef49d8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends: HaraldNordgren, Nyholm, lydell, linhduongtuan, LinusU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15."
      ],
      "metadata": {
        "id": "BRG2fbcEbvcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fraction_hierable = users[users['hireable'] == True]['email'].notna().mean()\n",
        "fraction_non_hierable = users[users['hireable'] == False]['email'].notna().mean()\n",
        "diff = fraction_hierable - fraction_non_hierable\n",
        "diff"
      ],
      "metadata": {
        "id": "AMF6TTFfQDn0",
        "outputId": "1aabb05e-360b-46b0-8fbc-0a02b8762c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16870967741935483"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16."
      ],
      "metadata": {
        "id": "DtdYn2m4hpKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "users = pd.read_csv('users.csv')\n",
        "\n",
        "new_users = users[users['name'].notna()].copy()\n",
        "new_users['surname'] = new_users['name'].str.split().str[-1].str.strip()\n",
        "surname_counts = new_users['surname'].value_counts()\n",
        "max_count = surname_counts.max()\n",
        "common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
        "common_surnames.sort()\n",
        "print(','.join(common_surnames))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojcHa4n5hZYr",
        "outputId": "77313ccb-ab7a-4215-becf-a76fd7a0232c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gustafsson,Persson\n"
          ]
        }
      ]
    }
  ]
}